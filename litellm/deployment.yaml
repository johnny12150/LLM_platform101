apiVersion: apps/v1
kind: Deployment
metadata:
  name: litellm
  namespace: llm-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: litellm
  template:
    metadata:
      labels:
        app: litellm
    spec:
      containers:
        - name: litellm
          image: docker.litellm.ai/berriai/litellm:v1.80.8-stable
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 4000
          env:
            - name: LITELLM_MODEL_NAME
              value: ollama/deepseek-r1:1.5b
            - name: LITELLM_MODEL_API_BASE
              value: http://ollama-api:11434
#            - name: LITELLM_MODEL_API_KEY
#              value: "EMPTY"

            # Optional
            - name: LITELLM_LOG
              value: "INFO"

            # Optional, Langfuse setting
            - name: LANGFUSE_PUBLIC_KEY
              value: "pk-lf-87353b57-7b49-474c-b59f-5597b990ac6f"
            - name: LANGFUSE_SECRET_KEY
              value: "sk-lf-b1bb676c-aa2f-4867-954f-5aa9754cd530"
            - name: LANGFUSE_HOST
              value: "http://langfuse-nodeport:3000"

            # Optional, DB setting
#            - name: DATABASE_URL
#              value: "postgres:////xxx"
#            - name: LITELLM_MASTER_KEY
#              value: "test123"

          command:
            - /bin/sh
            - -c
          args:
            - |
              set -e
              
              echo "
              model_list:
                - model_name: ${LITELLM_MODEL_NAME}
                  litellm_params:
                    model: ${LITELLM_MODEL_NAME}
                    api_base: ${LITELLM_MODEL_API_BASE}
              litellm_settings:
                success_callback: [\"langfuse\"]
              " > /tmp/config.yaml

              litellm --config /tmp/config.yaml --port 4000
